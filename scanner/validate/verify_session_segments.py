"""
Session Segment éªŒè¯è„šæœ¬
========================
éªŒè¯æ¯ä¸ª session çš„ segment è§„åˆ™ï¼š
1. segment ä» 0 å¼€å§‹è¿ç»­é€’å¢
2. éæœ€åä¸€ä¸ª segment çš„æ–‡ä»¶å¤§å°åº”çº¦ä¸º 1200MB
3. æœ€åä¸€ä¸ª segment çš„æ–‡ä»¶å¤§å°åº”å°äº 1200MB

æ”¯æŒè‡ªåŠ¨ä¿®å¤åŠŸèƒ½ï¼š
- æ£€æµ‹åˆ° front_file_size_bytes = 0 æ—¶ï¼Œè‡ªåŠ¨ä» OSS è¯»å–å¹¶æ›´æ–°

ä½¿ç”¨ç¤ºä¾‹:
  python -m scanner.validate.verify_session_segments
  python -m scanner.validate.verify_session_segments --auto-fix  # è‡ªåŠ¨ä¿®å¤é—®é¢˜
"""

import csv
import re
import sys
import os
import argparse
from pathlib import Path
from collections import defaultdict
from dotenv import load_dotenv
import oss2
import psycopg2

# é¡¹ç›®æ ¹ç›®å½•
project_root = Path(__file__).parent.parent.parent  # scanner/validate/verify_session_segments.py -> scanner/validate -> scanner -> é¡¹ç›®æ ¹ç›®å½•
sys.path.insert(0, str(project_root))

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(project_root / ".env")

EXPORTED_CSV_DIR = project_root / "ExportedCSV"


def parse_filesize(filesize_str: str) -> float:
    """è§£ææ–‡ä»¶å¤§å°å­—ç¬¦ä¸²ï¼Œè¿”å› MB æ•°å€¼"""
    if not filesize_str:
        return 0.0
    match = re.search(r'([\d.]+)\s*MB', filesize_str)
    if match:
        return float(match.group(1))
    return 0.0


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    try:
        conn = psycopg2.connect(
            host=os.getenv("PG_HOST"),
            database=os.getenv("PG_DATABASE"),
            user=os.getenv("PG_USER"),
            password=os.getenv("PG_PASSWORD"),
            port=os.getenv("PG_PORT", 5432)
        )
        return conn
    except Exception as e:
        print(f"âœ— æ— æ³•è¿æ¥åˆ°æ•°æ®åº“: {e}")
        return None


def get_oss_bucket():
    """è·å– OSS bucket è¿æ¥"""
    try:
        auth = oss2.Auth(
            os.getenv("OSS_ACCESS_KEY_ID"),
            os.getenv("OSS_ACCESS_KEY_SECRET")
        )
        bucket = oss2.Bucket(
            auth,
            os.getenv("OSS_ENDPOINT"),
            os.getenv("OSS_BUCKET_NAME")
        )
        return bucket
    except Exception as e:
        print(f"âœ— æ— æ³•è¿æ¥åˆ° OSS: {e}")
        return None


def fix_session_front_filesize(device_id: str, session_id: str, bucket, conn) -> bool:
    """
    ä¿®å¤ç‰¹å®š session çš„ front æ–‡ä»¶å¤§å°
    
    è¿”å›: æ˜¯å¦æˆåŠŸä¿®å¤
    """
    try:
        # åˆ—å‡ºè¯¥ session çš„æ‰€æœ‰ front æ–‡ä»¶
        prefix = f"{device_id}/{session_id}/segments/"
        
        front_files = {}
        for obj in oss2.ObjectIterator(bucket, prefix=prefix):
            filename = obj.key.split("/")[-1]
            
            # åªå¤„ç† front mp4 æ–‡ä»¶
            if "front" in filename and filename.endswith('.mp4'):
                # æå– segment ç¼–å·
                match = re.search(r'_(\d+)\.mp4$', filename)
                if match:
                    segment_number = match.group(1)
                    front_files[segment_number] = obj.size
        
        if not front_files:
            return False
        
        # æŸ¥è¯¢æ•°æ®åº“ä¸­éœ€è¦æ›´æ–°çš„è®°å½•
        with conn.cursor() as cur:
            cur.execute("""
                SELECT segment_number
                FROM fpv.segments
                WHERE session_id = %s AND (front_file_size_bytes = 0 OR front_file_size_bytes IS NULL)
                ORDER BY segment_number
            """, (session_id,))
            
            segments_to_fix = [row[0] for row in cur.fetchall()]
        
        if not segments_to_fix:
            return False
        
        # æ‰§è¡Œæ›´æ–°
        updates = []
        for segment_number in segments_to_fix:
            segment_str = str(segment_number).zfill(4)
            if segment_str in front_files:
                updates.append((front_files[segment_str], session_id, segment_number))
        
        if updates:
            with conn.cursor() as cur:
                cur.executemany("""
                    UPDATE fpv.segments
                    SET front_file_size_bytes = %s
                    WHERE session_id = %s AND segment_number = %s
                """, updates)
                conn.commit()
            
            print(f"      âœ“ å·²ä¿®å¤ {len(updates)} ä¸ª segment çš„ front æ–‡ä»¶å¤§å°")
            return True
        
        return False
        
    except Exception as e:
        print(f"      âœ— ä¿®å¤å¤±è´¥: {e}")
        conn.rollback()
        return False


def verify_session_segments(csv_file: str, auto_fix: bool = False):
    """
    éªŒè¯ session çš„ segment è§„åˆ™
    
    å‚æ•°:
        csv_file: CSVæ–‡ä»¶å
    """
    csv_path = EXPORTED_CSV_DIR / csv_file
    
    if not csv_path.exists():
        print(f"âœ— æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return
    
    print("=" * 80)
    print(f"Session Segment éªŒè¯")
    print("=" * 80)
    print(f"æ–‡ä»¶: {csv_file}")
    print(f"è‡ªåŠ¨ä¿®å¤: {'å¯ç”¨' if auto_fix else 'ç¦ç”¨'}")
    print()
    
    # å¦‚æœå¯ç”¨è‡ªåŠ¨ä¿®å¤ï¼Œè¿æ¥æ•°æ®åº“å’Œ OSS
    conn = None
    bucket = None
    if auto_fix:
        conn = get_db_connection()
        bucket = get_oss_bucket()
        if not conn or not bucket:
            print("âš ï¸  æ— æ³•è¿æ¥åˆ°æ•°æ®åº“æˆ–OSSï¼Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½å·²ç¦ç”¨")
            auto_fix = False
        else:
            print("âœ“ å·²è¿æ¥åˆ°æ•°æ®åº“å’ŒOSSï¼Œè‡ªåŠ¨ä¿®å¤åŠŸèƒ½å·²å¯ç”¨")
            print()
    
    # è¯»å–CSVæ–‡ä»¶
    with open(csv_path, 'r', encoding='utf-8') as f:
        # æ£€æµ‹æ˜¯å¦æœ‰è¡¨å¤´
        first_line = f.readline()
        f.seek(0)
        
        has_header = 'é‡‡é›†æ—¥æœŸ' in first_line or 'session_id' in first_line
        
        if has_header:
            reader = csv.DictReader(f)
            rows = list(reader)
        else:
            # æ— è¡¨å¤´ï¼Œæ‰‹åŠ¨æ„å»ºå­—å…¸
            reader = csv.reader(f)
            rows = []
            for row in reader:
                if len(row) >= 9:
                    rows.append({
                        'é‡‡é›†æ—¥æœŸ': row[0],
                        'é‡‡é›†æ—¶é—´': row[1],
                        'è®¾å¤‡ID': row[2],
                        'æ®µè½å·': row[3],
                        'å‘ä¸‹é•œå¤´è§†é¢‘é“¾æ¥': row[4],
                        'å‘å‰é•œå¤´è§†é¢‘é“¾æ¥': row[5],
                        'session_id': row[6],
                        'filesize': row[7],
                        'æ—¶é•¿': row[8]
                    })
    
    if not rows:
        print("âœ— æ–‡ä»¶ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯")
        return
    
    print(f"âœ“ è¯»å– {len(rows)} æ¡è®°å½•")
    print()
    
    # æŒ‰ session_id åˆ†ç»„
    sessions = defaultdict(list)
    
    for row in rows:
        session_id = row.get('session_id', '')
        segment_str = row.get('æ®µè½å·', '')
        filesize_str = row.get('filesize', '')
        device_id = row.get('è®¾å¤‡ID', '')
        
        try:
            segment = int(segment_str)
        except ValueError:
            segment = -1
        
        size_mb = parse_filesize(filesize_str)
        
        sessions[session_id].append({
            'segment': segment,
            'size_mb': size_mb,
            'filesize_str': filesize_str,
            'device_id': device_id
        })
    
    print(f"âœ“ å…± {len(sessions)} ä¸ª session")
    print()
    
    # éªŒè¯æ¯ä¸ª session
    print("=" * 80)
    print("éªŒè¯ç»“æœ")
    print("=" * 80)
    print()
    
    # ç»Ÿè®¡
    total_sessions = len(sessions)
    valid_sessions = 0
    invalid_sessions = 0
    
    # é—®é¢˜åˆ†ç±»
    issues = {
        'segment_gap': [],      # segment ä¸è¿ç»­
        'segment_order': [],    # segment é¡ºåºé”™è¯¯
        'size_too_small': [],   # éæœ€å segment æ–‡ä»¶å¤ªå°
        'last_too_large': [],   # æœ€å segment æ–‡ä»¶å¤ªå¤§
    }
    
    # æ–‡ä»¶å¤§å°é˜ˆå€¼
    NORMAL_SIZE_MIN = 1100  # MBï¼Œéæœ€å segment çš„æœ€å°å€¼ï¼ˆé‡ç‚¹æ£€æŸ¥æ˜¯å¦è¿œå°äº1200ï¼‰
    NORMAL_SIZE_MAX = 1300  # MBï¼Œéæœ€å segment çš„æœ€å¤§å€¼
    LAST_SIZE_MAX = 1210    # MBï¼Œæœ€å segment çš„æœ€å¤§å€¼ï¼ˆå…è®¸å¤šä¸€ç‚¹ç‚¹ï¼‰
    
    for session_id, segments in sorted(sessions.items()):
        # æŒ‰ segment æ’åº
        segments.sort(key=lambda x: x['segment'])
        
        device_id = segments[0]['device_id']
        has_issue = False
        session_issues = []
        
        # éªŒè¯1: segment åº”è¯¥ä» 0 å¼€å§‹è¿ç»­é€’å¢
        expected_segments = list(range(len(segments)))
        actual_segments = [s['segment'] for s in segments]
        
        if actual_segments != expected_segments:
            has_issue = True
            if actual_segments[0] != 0:
                session_issues.append(f"segment ä¸ä» 0 å¼€å§‹ï¼ˆå®é™…: {actual_segments[0]}ï¼‰")
                issues['segment_order'].append(session_id)
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰é—´éš”
                for i in range(len(actual_segments) - 1):
                    if actual_segments[i+1] != actual_segments[i] + 1:
                        session_issues.append(f"segment ä¸è¿ç»­: {actual_segments[i]} -> {actual_segments[i+1]}")
                        issues['segment_gap'].append(session_id)
                        break
        
        # éªŒè¯2: éæœ€åä¸€ä¸ª segment åº”è¯¥çº¦ä¸º 1200MBï¼ˆé‡ç‚¹æ£€æŸ¥ï¼‰
        for i, seg in enumerate(segments[:-1]):  # é™¤äº†æœ€åä¸€ä¸ª
            if seg['size_mb'] < NORMAL_SIZE_MIN:
                has_issue = True
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ front_file_size = 0 çš„é—®é¢˜
                if auto_fix and seg['size_mb'] > 0 and seg['size_mb'] < 700:
                    # å¯èƒ½æ˜¯åªæœ‰ down æ–‡ä»¶å¤§å°ï¼Œfront ä¸º 0
                    print(f"   ğŸ”§ æ£€æµ‹åˆ°å¯èƒ½çš„ front æ–‡ä»¶å¤§å°ç¼ºå¤±ï¼Œå°è¯•ä¿®å¤...")
                    if fix_session_front_filesize(device_id, session_id, bucket, conn):
                        session_issues.append(f"segment {seg['segment']} æ–‡ä»¶å¤ªå°: {seg['filesize_str']} (å·²å°è¯•ä¿®å¤)")
                    else:
                        session_issues.append(f"âš ï¸ segment {seg['segment']} æ–‡ä»¶å¤ªå°: {seg['filesize_str']} (ä¿®å¤å¤±è´¥)")
                else:
                    session_issues.append(f"âš ï¸ segment {seg['segment']} æ–‡ä»¶å¤ªå°: {seg['filesize_str']} (åº”çº¦ 1200MB)")
                
                if session_id not in issues['size_too_small']:
                    issues['size_too_small'].append(session_id)
            elif seg['size_mb'] > NORMAL_SIZE_MAX:
                has_issue = True
                session_issues.append(f"segment {seg['segment']} æ–‡ä»¶è¿‡å¤§: {seg['filesize_str']} (åº”çº¦ 1200MB)")
                if session_id not in issues['size_too_small']:
                    issues['size_too_small'].append(session_id)
        
        # éªŒè¯3: æœ€åä¸€ä¸ª segment åº”è¯¥å°äº 1200MB
        if len(segments) > 0:
            last_seg = segments[-1]
            if last_seg['size_mb'] >= LAST_SIZE_MAX:
                has_issue = True
                session_issues.append(f"æœ€å segment {last_seg['segment']} æ–‡ä»¶è¿‡å¤§: {last_seg['filesize_str']} (åº” < 1200MB)")
                issues['last_too_large'].append(session_id)
        
        # è¾“å‡ºç»“æœ
        if has_issue:
            invalid_sessions += 1
            print(f"âŒ {session_id} (è®¾å¤‡: {device_id})")
            print(f"   Segments: {len(segments)} ä¸ª {actual_segments}")
            for issue in session_issues:
                print(f"   - {issue}")
            
            # æ˜¾ç¤ºæ‰€æœ‰ segment çš„å¤§å°
            print(f"   æ–‡ä»¶å¤§å°:")
            for seg in segments:
                marker = "âœ“" if seg == segments[-1] and seg['size_mb'] < LAST_SIZE_MAX else \
                         "âœ“" if seg != segments[-1] and NORMAL_SIZE_MIN <= seg['size_mb'] <= NORMAL_SIZE_MAX else "âœ—"
                print(f"     {marker} segment {seg['segment']}: {seg['filesize_str']}")
            print()
        else:
            valid_sessions += 1
    
    # è¾“å‡ºç»Ÿè®¡
    print("=" * 80)
    print("ç»Ÿè®¡ç»“æœ")
    print("=" * 80)
    print(f"æ€» session æ•°:     {total_sessions}")
    print(f"âœ“ éªŒè¯é€šè¿‡:        {valid_sessions} ({valid_sessions/total_sessions*100:.1f}%)")
    print(f"âœ— éªŒè¯å¤±è´¥:        {invalid_sessions} ({invalid_sessions/total_sessions*100:.1f}%)")
    print()
    
    if invalid_sessions > 0:
        print("é—®é¢˜åˆ†ç±»:")
        if issues['segment_order']:
            print(f"  - Segment é¡ºåºé”™è¯¯: {len(issues['segment_order'])} ä¸ª")
        if issues['segment_gap']:
            print(f"  - Segment ä¸è¿ç»­:   {len(issues['segment_gap'])} ä¸ª")
        if issues['size_too_small']:
            print(f"  - âš ï¸ éæœ€åsegmentæ–‡ä»¶å¤§å°å¼‚å¸¸: {len(issues['size_too_small'])} ä¸ª (é‡ç‚¹å…³æ³¨)")
        if issues['last_too_large']:
            print(f"  - æœ€åsegmentæ–‡ä»¶è¿‡å¤§: {len(issues['last_too_large'])} ä¸ª")
    
    print()
    print("=" * 80)
    print("ç»“è®º:")
    print("=" * 80)
    
    if invalid_sessions == 0:
        print("âœ… æ‰€æœ‰ session çš„ segment è§„åˆ™éªŒè¯é€šè¿‡ï¼")
        print("   - æ‰€æœ‰ segment ä» 0 å¼€å§‹è¿ç»­é€’å¢")
        print("   - éæœ€å segment æ–‡ä»¶å¤§å°çº¦ä¸º 1200MB (1100-1300MB)")
        print("   - æœ€å segment æ–‡ä»¶å¤§å° â‰¤ 1210MB")
    else:
        print(f"âš ï¸  å‘ç° {invalid_sessions} ä¸ª session å­˜åœ¨é—®é¢˜")
        if issues['size_too_small']:
            print(f"\n   ğŸ” é‡ç‚¹å…³æ³¨ï¼š{len(issues['size_too_small'])} ä¸ª session çš„éæœ€åsegmentæ–‡ä»¶å¤§å°å¼‚å¸¸")
            print("      è¿™äº›segmentåº”è¯¥çº¦ä¸º1200MBï¼Œä½†å®é™…è¿œå°äºæˆ–è¿œå¤§äºæ­¤å€¼")
            if auto_fix:
                print("      å·²å°è¯•è‡ªåŠ¨ä¿®å¤ï¼Œå»ºè®®é‡æ–°å¯¼å‡ºCSVéªŒè¯ç»“æœ")
        print("\n   è¯·æ£€æŸ¥ä¸Šè¿°æ ‡è®°ä¸º âŒ çš„ session")
    
    print("=" * 80)
    
    # æ¸…ç†è¿æ¥
    if conn:
        conn.close()


def main():
    """ä¸»å‡½æ•°"""
    # ========================================
    # é…ç½®åŒºåŸŸï¼šåœ¨è¿™é‡ŒæŒ‡å®šè¦éªŒè¯çš„æ–‡ä»¶
    # ========================================
    CSV_FILE = "formatted_2026-01-19_2026-01-19_20260122_144132.csv"  # ä¿®å¤åçš„æ–‡ä»¶
    AUTO_FIX = True  # æ˜¯å¦è‡ªåŠ¨ä¿®å¤é—®é¢˜ï¼ˆæ”¹ä¸º False ç¦ç”¨è‡ªåŠ¨ä¿®å¤ï¼‰
    # ========================================
    
    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="éªŒè¯ Session Segment è§„åˆ™")
    parser.add_argument("--file", "-f", help="CSVæ–‡ä»¶å")
    parser.add_argument("--auto-fix", action="store_true", help="å¯ç”¨è‡ªåŠ¨ä¿®å¤")
    parser.add_argument("--no-fix", action="store_true", help="ç¦ç”¨è‡ªåŠ¨ä¿®å¤")
    args = parser.parse_args()
    
    # å‘½ä»¤è¡Œå‚æ•°ä¼˜å…ˆ
    csv_file = args.file or CSV_FILE
    if args.auto_fix:
        auto_fix = True
    elif args.no_fix:
        auto_fix = False
    else:
        auto_fix = AUTO_FIX
    
    print()
    print("Session Segment éªŒè¯å·¥å…·")
    print()
    
    verify_session_segments(csv_file, auto_fix)


if __name__ == "__main__":
    main()
